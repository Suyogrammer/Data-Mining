{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def perceptron_train(X, y, learning_rate=0.1, max_iteration=1000, gamma=0.1):\n",
        "    # Initialize weights and bias\n",
        "    w = np.zeros(X.shape[1])\n",
        "    b = 0\n",
        "    total_weight_change = 0\n",
        "\n",
        "    for iteration in range(max_iteration+1):\n",
        "        previous_w = np.copy(w)  # Track previous weights for weight change calculation\n",
        "        total_weight_change = 0  # Reset total weight change for each iteration\n",
        "\n",
        "        for i in range(len(y)):\n",
        "            # Calculate the linear output (w Â· X[i] + b)\n",
        "            pred = np.dot(X[i], w) + b\n",
        "\n",
        "            # Apply the activation function (threshold based prediction)\n",
        "            y_pred = 1 if pred > 0 else 0\n",
        "\n",
        "           # Update weights and bias if there is a misclassification\n",
        "            if y_pred != y[i]:\n",
        "                error = y[i] - y_pred\n",
        "                w += learning_rate * error * X[i]\n",
        "                b += learning_rate * error\n",
        "\n",
        "        # Calculate the total weight change\n",
        "        total_weight_change = np.linalg.norm(w - previous_w)\n",
        "\n",
        "        # Stop if weight change is less than gamma\n",
        "        if total_weight_change < gamma:\n",
        "            print(f\"Stopped after {iteration+1} iterations\")\n",
        "            break\n",
        "\n",
        "    return w, b, iteration\n",
        "\n",
        "# Perceptron prediction\n",
        "def perceptron_predict(X, w, b):\n",
        "    pred = np.dot(X, w) + b\n",
        "    return np.where(pred > 0, 1, 0)\n",
        "\n",
        "# K-Fold Cross-Validation Function\n",
        "def kfolds_cross_validation(X, y, k=5):\n",
        "    fold_size = len(X) // k\n",
        "    indices = np.arange(len(X))\n",
        "    np.random.shuffle(indices)  # Shuffle once at the beginning\n",
        "    X = X[indices]\n",
        "    y = y[indices]\n",
        "\n",
        "    accuracy_scores = []\n",
        "    iteration_per_fold = []\n",
        "\n",
        "    for fold in range(k):\n",
        "        # Defining the test indices for this fold\n",
        "        test_indices = indices[fold * fold_size:(fold + 1) * fold_size]\n",
        "        train_indices = np.setdiff1d(indices, test_indices)\n",
        "\n",
        "        # Train and Test splits data\n",
        "        X_train, y_train = X[train_indices], y[train_indices]\n",
        "        X_test, y_test = X[test_indices], y[test_indices]\n",
        "\n",
        "        w, b, iteration = perceptron_train(X_train, y_train)\n",
        "\n",
        "        # Predict on the test set\n",
        "        y_pred = perceptron_predict(X_test, w, b)\n",
        "\n",
        "        # Accuracy Calculation\n",
        "        accuracy = np.mean(y_pred == y_test) * 100\n",
        "        accuracy_scores.append(accuracy)\n",
        "        print(f\"Fold {fold + 1} Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "        # Iteration Calculation\n",
        "        iteration_per_fold.append(iteration)\n",
        "        print(f\"Fold {fold + 1} Iterations: {iteration}\")\n",
        "\n",
        "    return accuracy_scores, iteration_per_fold\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('Asgmnt1_data.txt', delimiter='\\s+', header=None)\n",
        "\n",
        "# Create class labels: first 8000 rows as class 0, and next 8000 rows as class 1\n",
        "labels = [0] * 8000 + [1] * 8000\n",
        "\n",
        "# Initialize 1 for wo (bias column)\n",
        "wo = [1] * 16000\n",
        "\n",
        "df.insert(0, 'weight(w0)', wo)\n",
        "\n",
        "# Add class labels as a new column in the dataframe\n",
        "df['class_label'] = labels\n",
        "\n",
        "# Shuffle the data\n",
        "shuffled_df = df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "# Extract features and labels\n",
        "X = shuffled_df.drop('class_label', axis=1).values  # Features\n",
        "y = shuffled_df['class_label'].values  # Labels\n",
        "\n",
        "# Perform the 5-fold cross-validation\n",
        "accuracy_per_fold, iteration_per_fold = kfolds_cross_validation(X, y, k=5)\n",
        "\n",
        "# Output per folds\n",
        "print(f\"Cross-Validation Accuracies: {accuracy_per_fold}\")\n",
        "print(f\"Number of Iterations per Fold: {iteration_per_fold}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bh20RYJvSruB",
        "outputId": "e0c78356-d8fc-4780-a487-d0f4d32bac9b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Accuracy: 50.56%\n",
            "Fold 1 Iterations: 1000\n",
            "Fold 2 Accuracy: 48.88%\n",
            "Fold 2 Iterations: 1000\n",
            "Fold 3 Accuracy: 49.84%\n",
            "Fold 3 Iterations: 1000\n",
            "Fold 4 Accuracy: 49.44%\n",
            "Fold 4 Iterations: 1000\n",
            "Fold 5 Accuracy: 49.41%\n",
            "Fold 5 Iterations: 1000\n",
            "Cross-Validation Accuracies: [50.5625, 48.875, 49.84375, 49.4375, 49.40625]\n",
            "Number of Iterations per Fold: [1000, 1000, 1000, 1000, 1000]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def haar_matrix(n):\n",
        "    if n == 1:\n",
        "        return np.array([[1]])  # Base case: 1x1 matrix\n",
        "\n",
        "    # Recursive call to build a smaller Haar matrix (n // 2 x n // 2)\n",
        "    h = haar_matrix(n // 2)\n",
        "\n",
        "    # Construct the larger Haar matrix using Kronecker products\n",
        "    h_n = np.kron(h, [1, 1])       # Top part of the Haar matrix\n",
        "    h_i = np.kron(np.eye(len(h)), [1, -1])  # Bottom part of the Haar matrix\n",
        "\n",
        "    # Stack the two parts vertically\n",
        "    h = np.vstack((h_n, h_i))\n",
        "\n",
        "    h = np.where(np.abs(h) < 1e-10, 0,h)\n",
        "\n",
        "    return h\n",
        "\n",
        "H_128 = haar_matrix(128)\n",
        "\n",
        "df = pd.read_csv('Asgmnt1_data.txt', delimiter='\\s+', header=None)\n",
        "df_array = df.values\n",
        "\n",
        "wavelet_transformed_data = np.dot(df_array, H_128.T)\n",
        "\n",
        "first_4_coeffs = wavelet_transformed_data[:, :4]\n",
        "\n",
        "wo = np.ones((16000, 1))  # Reshape as column\n",
        "labels = np.array([0] * 8000 + [1] * 8000).reshape(-1, 1)\n",
        "\n",
        "# Combine the coefficients, wo, and labels into a DataFrame\n",
        "first_4_df = pd.DataFrame(first_4_coeffs, columns=[f'coeff_{i}' for i in range(1, 5)])\n",
        "first_4_df['wo'] = wo\n",
        "first_4_df['class_label'] = labels\n",
        "\n",
        "first_4_df = first_4_df[['wo', 'coeff_1', 'coeff_2', 'coeff_3', 'coeff_4', 'class_label']]\n",
        "\n",
        "X = first_4_df.drop('class_label', axis=1).values\n",
        "y = first_4_df['class_label'].values\n",
        "\n",
        "accuracy_per_fold, iteration_per_fold = kfolds_cross_validation(X, y, k=5)\n",
        "\n",
        "print(f\"Cross-Validation Accuracies: {accuracy_per_fold}\")\n",
        "print(f\"Number of Iterations per Fold: {iteration_per_fold}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHa7BycOZdm6",
        "outputId": "e3ec610d-d6f1-4592-b5e8-f9605a92720c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Accuracy: 49.56%\n",
            "Fold 1 Iterations: 1000\n",
            "Fold 2 Accuracy: 48.72%\n",
            "Fold 2 Iterations: 1000\n",
            "Fold 3 Accuracy: 49.50%\n",
            "Fold 3 Iterations: 1000\n",
            "Fold 4 Accuracy: 50.22%\n",
            "Fold 4 Iterations: 1000\n",
            "Fold 5 Accuracy: 49.75%\n",
            "Fold 5 Iterations: 1000\n",
            "Cross-Validation Accuracies: [49.5625, 48.71875, 49.5, 50.21875, 49.75]\n",
            "Number of Iterations per Fold: [1000, 1000, 1000, 1000, 1000]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3vYbKWGxa3T3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}